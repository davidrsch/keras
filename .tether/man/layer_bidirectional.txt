Help on class Bidirectional in module keras.src.layers.rnn.bidirectional:

class Bidirectional(keras.src.layers.core.wrapper.Wrapper)
 |  Bidirectional(layer, merge_mode='concat', weights=None, backward_layer=None, **kwargs)
 |
 |  Bidirectional wrapper for RNNs.
 |
 |  Args:
 |      layer: `keras.layers.RNN` instance, such as
 |          `keras.layers.LSTM` or `keras.layers.GRU`.
 |          It could also be a `keras.layers.Layer` instance
 |          that meets the following criteria:
 |          1. Be a sequence-processing layer (accepts 3D+ inputs).
 |          2. Have a `go_backwards`, `return_sequences` and `return_state`
 |          attribute (with the same semantics as for the `RNN` class).
 |          3. Have an `input_spec` attribute.
 |          4. Implement serialization via `get_config()` and `from_config()`.
 |          Note that the recommended way to create new RNN layers is to write a
 |          custom RNN cell and use it with `keras.layers.RNN`, instead of
 |          subclassing `keras.layers.Layer` directly.
 |          When `return_sequences` is `True`, the output of the masked
 |          timestep will be zero regardless of the layer's original
 |          `zero_output_for_mask` value.
 |      merge_mode: Mode by which outputs of the forward and backward RNNs
 |          will be combined. One of `{"sum", "mul", "concat", "ave", None}`.
 |          If `None`, the outputs will not be combined,
 |          they will be returned as a list. Defaults to `"concat"`.
 |      backward_layer: Optional `keras.layers.RNN`,
 |          or `keras.layers.Layer` instance to be used to handle
 |          backwards input processing.
 |          If `backward_layer` is not provided, the layer instance passed
 |          as the `layer` argument will be used to generate the backward layer
 |          automatically.
 |          Note that the provided `backward_layer` layer should have properties
 |          matching those of the `layer` argument, in particular
 |          it should have the same values for `stateful`, `return_states`,
 |          `return_sequences`, etc. In addition, `backward_layer`
 |          and `layer` should have different `go_backwards` argument values.
 |          A `ValueError` will be raised if these requirements are not met.
 |
 |  Call arguments:
 |      The call arguments for this layer are the same as those of the
 |      wrapped RNN layer. Beware that when passing the `initial_state`
 |      argument during the call of this layer, the first half in the
 |      list of elements in the `initial_state` list will be passed to
 |      the forward RNN call and the last half in the list of elements
 |      will be passed to the backward RNN call.
 |
 |  Note: instantiating a `Bidirectional` layer from an existing RNN layer
 |  instance will not reuse the weights state of the RNN layer instance -- the
 |  `Bidirectional` layer will have freshly initialized weights.
 |
 |  Examples:
 |
 |  ```python
 |  model = Sequential([
 |      Input(shape=(5, 10)),
 |      Bidirectional(LSTM(10, return_sequences=True),
 |      Bidirectional(LSTM(10)),
 |      Dense(5, activation="softmax"),
 |  ])
 |  model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
 |
 |  # With custom backward layer
 |  forward_layer = LSTM(10, return_sequences=True)
 |  backward_layer = LSTM(10, activation='relu', return_sequences=True,
 |                        go_backwards=True)
 |  model = Sequential([
 |      Input(shape=(5, 10)),
 |      Bidirectional(forward_layer, backward_layer=backward_layer),
 |      Dense(5, activation="softmax"),
 |  ])
 |  model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
 |  ```
 |
 |  Method resolution order:
 |      Bidirectional
 |      keras.src.layers.core.wrapper.Wrapper
 |      keras.src.layers.layer.Layer
 |      keras.src.backend.tensorflow.layer.TFLayer
 |      keras.src.backend.tensorflow.trackable.KerasAutoTrackable
 |      tensorflow.python.trackable.autotrackable.AutoTrackable
 |      tensorflow.python.trackable.base.Trackable
 |      keras.src.ops.operation.Operation
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __init__(
 |    self,
 |    layer,
 |    merge_mode='concat',
 |    weights=None,
 |    backward_layer=None,
 |    **kwargs
 |  )
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  build(
 |    self,
 |    sequences_shape,
 |    initial_state_shape=None
 |  )
 |
 |  call(
 |    self,
 |    sequences,
 |    initial_state=None,
 |    mask=None,
 |    training=None
 |  )
 |
 |  compute_mask(
 |    self,
 |    _,
 |    mask
 |  )
 |
 |  compute_output_shape(
 |    self,
 |    sequences_shape,
 |    initial_state_shape=None
 |  )
 |
 |  get_config(self)
 |      Returns the config of the object.
 |
 |      An object config is a Python dictionary (serializable)
 |      containing the information needed to re-instantiate it.
 |
 |  reset_state(self)
 |
 |  reset_states(self)
 |
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |
 |  from_config(config, custom_objects=None) from builtins.type
 |      Creates a layer from its config.
 |
 |      This method is the reverse of `get_config`,
 |      capable of instantiating the same layer from the config
 |      dictionary. It does not handle layer connectivity
 |      (handled by Network), nor weights (handled by `set_weights`).
 |
 |      Args:
 |          config: A Python dictionary, typically the
 |              output of get_config.
 |
 |      Returns:
 |          A layer instance.
 |
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |
 |  states
 |

