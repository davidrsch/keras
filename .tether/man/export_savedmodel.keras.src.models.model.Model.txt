__signature__
keras.Model.export(
  self,
  filepath,
  format='tf_saved_model'
)
__doc__
Create a TF SavedModel artifact for inference.

**Note:** This can currently only be used with
the TensorFlow or JAX backends.

This method lets you export a model to a lightweight SavedModel artifact
that contains the model's forward pass only (its `call()` method)
and can be served via e.g. TF-Serving. The forward pass is registered
under the name `serve()` (see example below).

The original code of the model (including any custom layers you may
have used) is *no longer* necessary to reload the artifact -- it is
entirely standalone.

Args:
    filepath: `str` or `pathlib.Path` object. Path where to save
        the artifact.

Example:

```python
# Create the artifact
model.export("path/to/location")

# Later, in a different process / environment...
reloaded_artifact = tf.saved_model.load("path/to/location")
predictions = reloaded_artifact.serve(input_data)
```

If you would like to customize your serving endpoints, you can
use the lower-level `keras.export.ExportArchive` class. The
`export()` method relies on `ExportArchive` internally.

