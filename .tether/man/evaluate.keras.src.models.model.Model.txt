__signature__
keras.Model.evaluate(
  self,
  x=None,
  y=None,
  batch_size=None,
  verbose='auto',
  sample_weight=None,
  steps=None,
  callbacks=None,
  return_dict=False,
  **kwargs
)
__doc__
Returns the loss value & metrics values for the model in test mode.

Computation is done in batches (see the `batch_size` arg.)

Args:
    x: Input data. It can be:
        - A NumPy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
        - A backend-native tensor, or a list of tensors
        (in case the model has multiple inputs).
        - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
        - A `keras.utils.PyDataset` returning `(inputs, targets)` or
        `(inputs, targets, sample_weights)`.
        - A `tf.data.Dataset` yielding `(inputs, targets)` or
        `(inputs, targets, sample_weights)`.
        - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`
        or `(inputs, targets, sample_weights)`.
        - A Python generator function yielding `(inputs, targets)` or
        `(inputs, targets, sample_weights)`.
    y: Target data. Like the input data `x`, it can be either NumPy
        array(s) or backend-native tensor(s). If `x` is a
        `keras.utils.PyDataset`, `tf.data.Dataset`,
        `torch.utils.data.DataLoader` or a Python generator function,
        `y` should not be specified since targets will be obtained from
        `x`.
    batch_size: Integer or `None`.
        Number of samples per batch of computation.
        If unspecified, `batch_size` will default to 32.
        Do not specify the `batch_size` if your input data `x` is a
        `keras.utils.PyDataset`, `tf.data.Dataset`,
        `torch.utils.data.DataLoader` or Python generator function
        since they generate batches.
    verbose: `"auto"`, 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = single line.
        `"auto"` becomes 1 for most cases.
        Note that the progress bar is not
        particularly useful when logged to a file, so `verbose=2` is
        recommended when not running interactively
        (e.g. in a production environment). Defaults to `"auto"`.
    sample_weight: Optional NumPy array or tensor of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        NumPy array or tensor with the same length as the input samples
        (1:1 mapping between weights and samples), or in the case of
        temporal data, you can pass a 2D NumPy array or tensor with
        shape `(samples, sequence_length)` to apply a different weight
        to every timestep of every sample.
        This argument is not supported when `x` is a
        `keras.utils.PyDataset`, `tf.data.Dataset`,
        `torch.utils.data.DataLoader` or Python generator function.
        Instead, provide `sample_weights` as the third element of `x`.
        Note that sample weighting does not apply to metrics specified
        via the `metrics` argument in `compile()`. To apply sample
        weighting to your metrics, you can specify them via the
        `weighted_metrics` in `compile()` instead.
    steps: Integer or `None`.
        Total number of steps (batches of samples) to draw before
        declaring the evaluation round finished. If `steps` is `None`,
        it will run until `x` is exhausted. In the case of an infinitely
        repeating dataset, it will run indefinitely.
    callbacks: List of `keras.callbacks.Callback` instances.
        List of callbacks to apply during evaluation.
    return_dict: If `True`, loss and metric results are returned as a
        dict, with each key being the name of the metric.
        If `False`, they are returned as a list.

Returns:
    Scalar test loss (if the model has a single output and no metrics)
    or list of scalars (if the model has multiple outputs
    and/or metrics). The attribute `model.metrics_names` will give you
    the display labels for the scalar outputs.

