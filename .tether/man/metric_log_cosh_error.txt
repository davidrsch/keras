Help on class LogCoshError in module keras.src.metrics.regression_metrics:

class LogCoshError(keras.src.metrics.reduction_metrics.MeanMetricWrapper)
 |  LogCoshError(name='logcosh', dtype=None)
 |
 |  Computes the logarithm of the hyperbolic cosine of the prediction error.
 |
 |  Formula:
 |
 |  ```python
 |  error = y_pred - y_true
 |  logcosh = mean(log((exp(error) + exp(-error))/2), axis=-1)
 |  ```
 |
 |  Args:
 |      name: (Optional) string name of the metric instance.
 |      dtype: (Optional) data type of the metric result.
 |
 |  Example:
 |
 |  Example:
 |
 |  >>> m = keras.metrics.LogCoshError()
 |  >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]])
 |  >>> m.result()
 |  0.10844523
 |  >>> m.reset_state()
 |  >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]],
 |  ...                sample_weight=[1, 0])
 |  >>> m.result()
 |  0.21689045
 |
 |  Usage with `compile()` API:
 |
 |  ```python
 |  model.compile(optimizer='sgd',
 |                loss='mse',
 |                metrics=[keras.metrics.LogCoshError()])
 |  ```
 |
 |  Method resolution order:
 |      LogCoshError
 |      keras.src.metrics.reduction_metrics.MeanMetricWrapper
 |      keras.src.metrics.reduction_metrics.Mean
 |      keras.src.metrics.metric.Metric
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __init__(
 |    self,
 |    name='logcosh',
 |    dtype=None
 |  )
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  get_config(self)
 |      Return the serializable config of the metric.
 |

