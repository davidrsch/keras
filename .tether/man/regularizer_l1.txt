Help on class L1 in module keras.src.regularizers.regularizers:

class L1(Regularizer)
 |  L1(l1=0.01)
 |
 |  A regularizer that applies a L1 regularization penalty.
 |
 |  The L1 regularization penalty is computed as:
 |  `loss = l1 * reduce_sum(abs(x))`
 |
 |  L1 may be passed to a layer as a string identifier:
 |
 |  >>> dense = Dense(3, kernel_regularizer='l1')
 |
 |  In this case, the default value used is `l1=0.01`.
 |
 |  Arguments:
 |      l1: float, L1 regularization factor.
 |
 |  Method resolution order:
 |      L1
 |      Regularizer
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __call__(self, x)
 |      Compute a regularization penalty from an input tensor.
 |
 |  __init__(self, l1=0.01)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  get_config(self)
 |      Returns the config of the regularizer.
 |
 |      An regularizer config is a Python dictionary (serializable)
 |      containing all configuration parameters of the regularizer.
 |      The same regularizer can be reinstantiated later
 |      (without any saved state) from this configuration.
 |
 |      This method is optional if you are just training and executing models,
 |      exporting to and from SavedModels, or using weight checkpoints.
 |
 |      This method is required for Keras `model_to_estimator`, saving and
 |      loading models to HDF5 formats, Keras model cloning, some visualization
 |      utilities, and exporting models to and from JSON.
 |
 |      Returns:
 |          Python dictionary.
 |
