Help on class Model in module keras.src.models.model:

class Model(keras.src.backend.tensorflow.trainer.TensorFlowTrainer, keras.src.trainers.trainer.Trainer, keras.src.layers.layer.Layer)
 |  Model(*args, **kwargs)
 |
 |  A model grouping layers into an object with training/inference features.
 |
 |  There are three ways to instantiate a `Model`:
 |
 |  ## With the "Functional API"
 |
 |  You start from `Input`,
 |  you chain layer calls to specify the model's forward pass,
 |  and finally you create your model from inputs and outputs:
 |
 |  ```python
 |  inputs = keras.Input(shape=(37,))
 |  x = keras.layers.Dense(32, activation="relu")(inputs)
 |  outputs = keras.layers.Dense(5, activation="softmax")(x)
 |  model = keras.Model(inputs=inputs, outputs=outputs)
 |  ```
 |
 |  Note: Only dicts, lists, and tuples of input tensors are supported. Nested
 |  inputs are not supported (e.g. lists of list or dicts of dict).
 |
 |  A new Functional API model can also be created by using the
 |  intermediate tensors. This enables you to quickly extract sub-components
 |  of the model.
 |
 |  Example:
 |
 |  ```python
 |  inputs = keras.Input(shape=(None, None, 3))
 |  processed = keras.layers.RandomCrop(width=128, height=128)(inputs)
 |  conv = keras.layers.Conv2D(filters=32, kernel_size=3)(processed)
 |  pooling = keras.layers.GlobalAveragePooling2D()(conv)
 |  feature = keras.layers.Dense(10)(pooling)
 |
 |  full_model = keras.Model(inputs, feature)
 |  backbone = keras.Model(processed, conv)
 |  activations = keras.Model(conv, feature)
 |  ```
 |
 |  Note that the `backbone` and `activations` models are not
 |  created with `keras.Input` objects, but with the tensors that originate
 |  from `keras.Input` objects. Under the hood, the layers and weights will
 |  be shared across these models, so that user can train the `full_model`, and
 |  use `backbone` or `activations` to do feature extraction.
 |  The inputs and outputs of the model can be nested structures of tensors as
 |  well, and the created models are standard Functional API models that support
 |  all the existing APIs.
 |
 |  ## By subclassing the `Model` class
 |
 |  In that case, you should define your
 |  layers in `__init__()` and you should implement the model's forward pass
 |  in `call()`.
 |
 |  ```python
 |  class MyModel(keras.Model):
 |      def __init__(self):
 |          super().__init__()
 |          self.dense1 = keras.layers.Dense(32, activation="relu")
 |          self.dense2 = keras.layers.Dense(5, activation="softmax")
 |
 |      def call(self, inputs):
 |          x = self.dense1(inputs)
 |          return self.dense2(x)
 |
 |  model = MyModel()
 |  ```
 |
 |  If you subclass `Model`, you can optionally have
 |  a `training` argument (boolean) in `call()`, which you can use to specify
 |  a different behavior in training and inference:
 |
 |  ```python
 |  class MyModel(keras.Model):
 |      def __init__(self):
 |          super().__init__()
 |          self.dense1 = keras.layers.Dense(32, activation="relu")
 |          self.dense2 = keras.layers.Dense(5, activation="softmax")
 |          self.dropout = keras.layers.Dropout(0.5)
 |
 |      def call(self, inputs, training=False):
 |          x = self.dense1(inputs)
 |          x = self.dropout(x, training=training)
 |          return self.dense2(x)
 |
 |  model = MyModel()
 |  ```
 |
 |  Once the model is created, you can config the model with losses and metrics
 |  with `model.compile()`, train the model with `model.fit()`, or use the model
 |  to do prediction with `model.predict()`.
 |
 |  ## With the `Sequential` class
 |
 |  In addition, `keras.Sequential` is a special case of model where
 |  the model is purely a stack of single-input, single-output layers.
 |
 |  ```python
 |  model = keras.Sequential([
 |      keras.Input(shape=(None, None, 3)),
 |      keras.layers.Conv2D(filters=32, kernel_size=3),
 |  ])
 |  ```
 |
 |  Method resolution order:
 |      Model
 |      keras.src.backend.tensorflow.trainer.TensorFlowTrainer
 |      keras.src.trainers.trainer.Trainer
 |      keras.src.layers.layer.Layer
 |      keras.src.backend.tensorflow.layer.TFLayer
 |      keras.src.backend.tensorflow.trackable.KerasAutoTrackable
 |      tensorflow.python.trackable.autotrackable.AutoTrackable
 |      tensorflow.python.trackable.base.Trackable
 |      keras.src.ops.operation.Operation
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __init__(
 |    self,
 |    *args,
 |    **kwargs
 |  )
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  __reduce__(self)
 |      __reduce__ is used to customize the behavior of `pickle.pickle()`.
 |
 |      The method returns a tuple of two elements: a function, and a list of
 |      arguments to pass to that function.  In this case we just leverage the
 |      keras saving library.
 |
 |  build_from_config(self, config)
 |      Builds the layer's states with the supplied config dict.
 |
 |      By default, this method calls the `build(config["input_shape"])` method,
 |      which creates weights based on the layer's input shape in the supplied
 |      config. If your config contains other information needed to load the
 |      layer's state, you should override this method.
 |
 |      Args:
 |          config: Dict containing the input shape associated with this layer.
 |
 |  call(
 |    self,
 |    *args,
 |    **kwargs
 |  )
 |
 |  export(
 |    self,
 |    filepath,
 |    format='tf_saved_model'
 |  )
 |      Create a TF SavedModel artifact for inference.
 |
 |      **Note:** This can currently only be used with
 |      the TensorFlow or JAX backends.
 |
 |      This method lets you export a model to a lightweight SavedModel artifact
 |      that contains the model's forward pass only (its `call()` method)
 |      and can be served via e.g. TF-Serving. The forward pass is registered
 |      under the name `serve()` (see example below).
 |
 |      The original code of the model (including any custom layers you may
 |      have used) is *no longer* necessary to reload the artifact -- it is
 |      entirely standalone.
 |
 |      Args:
 |          filepath: `str` or `pathlib.Path` object. Path where to save
 |              the artifact.
 |
 |      Example:
 |
 |      ```python
 |      # Create the artifact
 |      model.export("path/to/location")
 |
 |      # Later, in a different process / environment...
 |      reloaded_artifact = tf.saved_model.load("path/to/location")
 |      predictions = reloaded_artifact.serve(input_data)
 |      ```
 |
 |      If you would like to customize your serving endpoints, you can
 |      use the lower-level `keras.export.ExportArchive` class. The
 |      `export()` method relies on `ExportArchive` internally.
 |
 |  get_layer(
 |    self,
 |    name=None,
 |    index=None
 |  )
 |      Retrieves a layer based on either its name (unique) or index.
 |
 |      If `name` and `index` are both provided, `index` will take precedence.
 |      Indices are based on order of horizontal graph traversal (bottom-up).
 |
 |      Args:
 |          name: String, name of layer.
 |          index: Integer, index of layer.
 |
 |      Returns:
 |          A layer instance.
 |
 |  load_weights(
 |    self,
 |    filepath,
 |    skip_mismatch=False,
 |    **kwargs
 |  )
 |      Load weights from a file saved via `save_weights()`.
 |
 |      Weights are loaded based on the network's
 |      topology. This means the architecture should be the same as when the
 |      weights were saved. Note that layers that don't have weights are not
 |      taken into account in the topological ordering, so adding or removing
 |      layers is fine as long as they don't have weights.
 |
 |      **Partial weight loading**
 |
 |      If you have modified your model, for instance by adding a new layer
 |      (with weights) or by changing the shape of the weights of a layer,
 |      you can choose to ignore errors and continue loading
 |      by setting `skip_mismatch=True`. In this case any layer with
 |      mismatching weights will be skipped. A warning will be displayed
 |      for each skipped layer.
 |
 |      Args:
 |          filepath: String, path to the weights file to load.
 |              It can either be a `.weights.h5` file
 |              or a legacy `.h5` weights file.
 |          skip_mismatch: Boolean, whether to skip loading of layers where
 |              there is a mismatch in the number of weights, or a mismatch in
 |              the shape of the weights.
 |
 |  quantize(self, mode)
 |      Quantize the weights of the model.
 |
 |      Note that the model must be built first before calling this method.
 |      `quantize` will recursively call `quantize(mode)` in all layers and
 |      will be skipped if the layer doesn't implement the function.
 |
 |      Args:
 |          mode: The mode of the quantization. Only 'int8' is supported at this
 |              time.
 |
 |  save(
 |    self,
 |    filepath,
 |    overwrite=True,
 |    **kwargs
 |  )
 |      Saves a model as a `.keras` file.
 |
 |      Args:
 |          filepath: `str` or `pathlib.Path` object. Path where to save
 |              the model. Must end in `.keras`.
 |          overwrite: Whether we should overwrite any existing model at
 |              the target location, or instead ask the user via
 |              an interactive prompt.
 |          save_format: The `save_format` argument is deprecated in Keras 3.
 |              Format to use, as a string. Only the `"keras"` format is
 |              supported at this time.
 |
 |      Example:
 |
 |      ```python
 |      model = keras.Sequential(
 |          [
 |              keras.layers.Dense(5, input_shape=(3,)),
 |              keras.layers.Softmax(),
 |          ],
 |      )
 |      model.save("model.keras")
 |      loaded_model = keras.saving.load_model("model.keras")
 |      x = keras.random.uniform((10, 3))
 |      assert np.allclose(model.predict(x), loaded_model.predict(x))
 |      ```
 |
 |      Note that `model.save()` is an alias for `keras.saving.save_model()`.
 |
 |      The saved `.keras` file contains:
 |
 |      - The model's configuration (architecture)
 |      - The model's weights
 |      - The model's optimizer's state (if any)
 |
 |      Thus models can be reinstantiated in the exact same state.
 |
 |  save_weights(
 |    self,
 |    filepath,
 |    overwrite=True
 |  )
 |      Saves all layer weights to a `.weights.h5` file.
 |
 |      Args:
 |          filepath: `str` or `pathlib.Path` object.
 |              Path where to save the model. Must end in `.weights.h5`.
 |          overwrite: Whether we should overwrite any existing model
 |              at the target location, or instead ask the user
 |              via an interactive prompt.
 |
 |  summary(
 |    self,
 |    line_length=None,
 |    positions=None,
 |    print_fn=None,
 |    expand_nested=False,
 |    show_trainable=False,
 |    layer_range=None
 |  )
 |      Prints a string summary of the network.
 |
 |      Args:
 |          line_length: Total length of printed lines
 |              (e.g. set this to adapt the display to different
 |              terminal window sizes).
 |          positions: Relative or absolute positions of log elements
 |              in each line. If not provided, becomes
 |              `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.
 |          print_fn: Print function to use. By default, prints to `stdout`.
 |              If `stdout` doesn't work in your environment, change to `print`.
 |              It will be called on each line of the summary.
 |              You can set it to a custom function
 |              in order to capture the string summary.
 |          expand_nested: Whether to expand the nested models.
 |              Defaults to `False`.
 |          show_trainable: Whether to show if a layer is trainable.
 |              Defaults to `False`.
 |          layer_range: a list or tuple of 2 strings,
 |              which is the starting layer name and ending layer name
 |              (both inclusive) indicating the range of layers to be printed
 |              in summary. It also accepts regex patterns instead of exact
 |              name. In such case, start predicate will be the first element
 |              it matches to `layer_range[0]` and the end predicate will be
 |              the last element it matches to `layer_range[1]`.
 |              By default `None` which considers all layers of model.
 |
 |      Raises:
 |          ValueError: if `summary()` is called before the model is built.
 |
 |  to_json(self, **kwargs)
 |      Returns a JSON string containing the network configuration.
 |
 |      To load a network from a JSON save file, use
 |      `keras.models.model_from_json(json_string, custom_objects={...})`.
 |
 |      Args:
 |          **kwargs: Additional keyword arguments to be passed to
 |              `json.dumps()`.
 |
 |      Returns:
 |          A JSON string.
 |
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |
 |  from_config(config, custom_objects=None) from builtins.type
 |      Creates a layer from its config.
 |
 |      This method is the reverse of `get_config`,
 |      capable of instantiating the same layer from the config
 |      dictionary. It does not handle layer connectivity
 |      (handled by Network), nor weights (handled by `set_weights`).
 |
 |      Args:
 |          config: A Python dictionary, typically the
 |              output of get_config.
 |
 |      Returns:
 |          A layer instance.
 |
 |  ----------------------------------------------------------------------
 |  Static methods defined here:
 |
 |  __new__(
 |    cls,
 |    *args,
 |    **kwargs
 |  )
 |      Create and return a new object.  See help(type) for accurate signature.
 |
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |
 |  layers
 |

