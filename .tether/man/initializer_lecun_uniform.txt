Help on class LecunUniform in module keras.src.initializers.random_initializers:

class LecunUniform(VarianceScaling)
 |  LecunUniform(seed=None)
 |
 |  Lecun uniform initializer.
 |
 |  Draws samples from a uniform distribution within `[-limit, limit]`, where
 |  `limit = sqrt(3 / fan_in)` (`fan_in` is the number of input units in the
 |  weight tensor).
 |
 |  Examples:
 |
 |  >>> # Standalone usage:
 |  >>> initializer = LecunUniform()
 |  >>> values = initializer(shape=(2, 2))
 |
 |  >>> # Usage in a Keras layer:
 |  >>> initializer = LecunUniform()
 |  >>> layer = Dense(3, kernel_initializer=initializer)
 |
 |  Args:
 |      seed: A Python integer or instance of
 |          `keras.backend.SeedGenerator`.
 |          Used to make the behavior of the initializer
 |          deterministic. Note that an initializer seeded with an integer
 |          or `None` (unseeded) will produce the same random values
 |          across multiple calls. To get different random values
 |          across multiple calls, use as seed an instance
 |          of `keras.backend.SeedGenerator`.
 |
 |  Reference:
 |
 |  - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)
 |
 |  Method resolution order:
 |      LecunUniform
 |      VarianceScaling
 |      keras.src.initializers.initializer.Initializer
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __init__(self, seed=None)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  get_config(self)
 |      Returns the initializer's configuration as a JSON-serializable dict.
 |
 |      Returns:
 |          A JSON-serializable Python dict.
 |
